import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

load_dotenv()

# â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ğŸ’° ëŒ€ì¶œ ì§„ë‹¨ AI ìƒë‹´ì‚¬", page_icon="ğŸ’°", layout="centered")
st.title("ğŸ’° ê°œì¸ ë§ì¶¤ ëŒ€ì¶œ ì§„ë‹¨ AI ìƒë‹´ì‚¬")
st.caption("íŒŒì¸íŠœë‹ëœ ê¸ˆìœµ ì „ë¬¸ ëª¨ë¸ | `ft:gpt-4.1-nano-2025-04-14:fininsight:finance-expert:DAxB4H7H`")

# â”€â”€ íŒŒì¸íŠœë‹ ëª¨ë¸ ID â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FINETUNED_MODEL = "ft:gpt-4.1-nano-2025-04-14:fininsight:finance-expert:DAxB4H7H"

# â”€â”€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ê¸ˆìœµ ëŒ€ì¶œ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì¬ì • ìƒí™©(ì—°ì†Œë“, ì‹ ìš©ì ìˆ˜, ê¸°ì¡´ ëŒ€ì¶œ, í¬ë§ ëŒ€ì¶œì•¡ ë“±)ì„ íŒŒì•…í•˜ì—¬
DSR(ì´ë¶€ì±„ì›ë¦¬ê¸ˆìƒí™˜ë¹„ìœ¨), DTI, í•œë„ ê°€ëŠ¥ì„± ë“±ì„ ë¶„ì„í•˜ê³  ë§ì¶¤ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

ë‹µë³€ í˜•ì‹:
- ì •ì˜: ê´€ë ¨ ê¸ˆìœµ ê°œë… 1~2ì¤„ ì„¤ëª…
- í•µì‹¬: â‘  â‘¡ â‘¢ í˜•íƒœë¡œ í•µì‹¬ ë¶„ì„ 3ê°€ì§€
- ì˜ˆì‹œ: êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì˜ˆì‹œ
- ì£¼ì˜/íŒ: ì‹¤ìš©ì ì¸ ì¡°ì–¸

ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ í•„ìš”í•œ ì •ë³´ë¥¼ ì •ì¤‘íˆ ìš”ì²­í•˜ì„¸ìš”.
ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

# â”€â”€ LangChain ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def get_llm():
    return ChatOpenAI(
        model=FINETUNED_MODEL,
        temperature=0,
        streaming=True,
    )

llm = get_llm()

# â”€â”€ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    # LangChain "ë©”ì‹œì§€ ê°ì²´" ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬
    st.session_state.messages = []
if "display_messages" not in st.session_state:
    # í™”ë©´ í‘œì‹œìš© (role, content) "ë”•ì…”ë„ˆë¦¬" ë¦¬ìŠ¤íŠ¸ -> í™”ë©´ìƒì— ë©”ì‹œì§€ê°ì²´ê°€ ì•„ë‹Œ contentì— í•´ë‹¹ë˜ëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ê¸° ìœ„í•œ ìš©ë„
    st.session_state.display_messages = []

# â”€â”€ ì‚¬ì´ë“œë°”: ì‚¬ìš©ì í”„ë¡œí•„ ì…ë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ğŸ“‹ ë‚´ ê¸ˆìœµ í”„ë¡œí•„")
    st.caption("ì…ë ¥ ì‹œ ë” ì •í™•í•œ ì§„ë‹¨ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    loan_purpose  = st.selectbox("ëŒ€ì¶œ ëª©ì ", ["ì„ íƒ", "ì „ì„¸ìê¸ˆ", "ì£¼íƒêµ¬ì…", "ì‹ ìš©ëŒ€ì¶œ", "ì‚¬ì—…ìê¸ˆ", "ê¸°íƒ€"])
    annual_income = st.number_input("ì—°ì†Œë“ (ë§Œì›)",    min_value=2000, max_value=100000, value=3000, step=10)
    credit_score  = st.number_input("ì‹ ìš©ì ìˆ˜ (ì )",    min_value=0, max_value=1000,   value=0, step=10)
    existing_loan = st.number_input("ê¸°ì¡´ ì›” ìƒí™˜ì•¡ (ë§Œì›)", min_value=0, max_value=10000, value=100, step=10)
    target_amount = st.number_input("í¬ë§ ëŒ€ì¶œì•¡ (ë§Œì›)", min_value=0, max_value=500000, value=20000, step=500)

    # ì…ë ¥ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ user prompt ì‘ì„± 
    if st.button("ğŸ“Š í”„ë¡œí•„ ê¸°ë°˜ ì§„ë‹¨ ì‹œì‘", use_container_width=True):
        if annual_income > 0:
            profile_msg = f"""ì œ ê¸ˆìœµ í”„ë¡œí•„ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
- ì—°ì†Œë“: {annual_income:,}ë§Œì›
- ì‹ ìš©ì ìˆ˜: {credit_score}ì {"(ë¯¸ì…ë ¥)" if credit_score == 0 else ""}
- ê¸°ì¡´ ì›” ìƒí™˜ì•¡: {existing_loan}ë§Œì›
- ëŒ€ì¶œ ëª©ì : {loan_purpose if loan_purpose != "ì„ íƒ" else "ë¯¸ì •"}
- í¬ë§ ëŒ€ì¶œì•¡: {f"{target_amount:,}ë§Œì›" if target_amount > 0 else "ë¯¸ì •"}

í˜„ì¬ ìƒí™©ì—ì„œ ëŒ€ì¶œ ê°€ëŠ¥ì„±ê³¼ ì˜ˆìƒ í•œë„ë¥¼ ì§„ë‹¨í•´ì£¼ì„¸ìš”."""
            st.session_state.messages.append(HumanMessage(content=profile_msg))
            st.session_state.display_messages.append({"role": "user", "content": profile_msg})
            st.rerun() # í˜„ì¬ ì—…ë°ì´íŠ¸ëœ ë‚´ìš©ìœ¼ë¡œ ë‹¤ì‹œ ìŠ¤í¬ë¦½íŠ¸íŒŒì¼ì„ ì²˜ìŒë¶€í„° ì‹¤í–‰í•˜ë¼ëŠ” ì˜ë¯¸ -> UIì— ì¦‰ì‹œ ë°˜ì˜í•˜ê¸° ìœ„í•¨
        else:
            st.warning("ì—°ì†Œë“ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.divider()
    st.markdown(f"**ğŸ¤– ì‚¬ìš© ëª¨ë¸**\n\n`{FINETUNED_MODEL[:30]}...`")
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.display_messages = []
        st.rerun()
        
# â”€â”€ í™˜ì˜ ë©”ì‹œì§€ (ëŒ€í™” ì—†ì„ ë•Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.display_messages:
    with st.chat_message("assistant", avatar="ğŸ’¼"):
        st.markdown("""ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹ **ê¸ˆìœµ ëŒ€ì¶œ ì „ë¬¸ íŒŒì¸íŠœë‹ ëª¨ë¸** ê¸°ë°˜ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ìƒë‹´ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤:
- ğŸ“Œ **ëŒ€ì¶œ í•œë„ ì˜ˆì¸¡** â€” ì—°ì†Œë“Â·ì‹ ìš©ì ìˆ˜ ê¸°ë°˜ DSR/DTI ë¶„ì„
- ğŸ“Œ **ì „ì„¸Â·ì£¼ë‹´ëŒ€Â·ì‹ ìš©ëŒ€ì¶œ** â€” ëª©ì ë³„ ëŒ€ì¶œ ê°€ëŠ¥ì„± ì§„ë‹¨
- ğŸ“Œ **ê¸ˆë¦¬ ì ˆê° ì „ëµ** â€” ì‹ ìš©ì ìˆ˜ ê°œì„  & ëŒ€ì¶œ êµ¬ì¡° ìµœì í™”
- ğŸ“Œ **ë§ì¶¤ ìƒí™˜ ê³„íš** â€” ì†Œë“ ëŒ€ë¹„ ì•ˆì „í•œ ìƒí™˜ì•¡ ì‚°ì¶œ

ì™¼ìª½ ì‚¬ì´ë“œë°”ì— í”„ë¡œí•„ì„ ì…ë ¥í•˜ê±°ë‚˜, ì§ì ‘ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”! ğŸ˜Š""")


# â”€â”€ ëŒ€í™” ì´ë ¥ í‘œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for msg in st.session_state.display_messages:
    avatar = "ğŸ§‘" if msg["role"] == "user" else "ğŸ’¼"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# â”€â”€ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# := -> ëŒ€ì…í•˜ë©´ì„œ ë™ì‹œì— ì¡°ê±´ ê²€ì‚¬ 
# --- ì•„ë˜ì™€ ë™ì¼ ----
# prompt = st.chat_input("...")
# if prompt:
# -----------------
if prompt := st.chat_input("ì˜ˆ) ì—°ë´‰ 5000ë§Œì›, ì‹ ìš©ì ìˆ˜ 750ì ì´ë©´ ì‹ ìš©ëŒ€ì¶œ ì–¼ë§ˆë‚˜ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?"):
    # sessiont_state ì—…ë°ì´íŠ¸
    st.session_state.messages.append(HumanMessage(content=prompt))
    st.session_state.display_messages.append({"role": "user", "content": prompt})
    # í™”ë©´ ì¶œë ¥ 
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(prompt)

# â”€â”€ AI ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# messagesì— ë§ˆì§€ë§‰ìœ¼ë¡œ ë‹´ê¸´ ë©”ì‹œì§€ê°€ HumanMessageì¸ì§€ í™•ì¸ í›„ í•´ë‹¹ ë©”ì‹œì§€ë¡œ AIì‘ë‹µ ìƒì„±
if st.session_state.messages and isinstance(st.session_state.messages[-1], HumanMessage):
    with st.chat_message("assistant", avatar="ğŸ’¼"):
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ + ì „ì²´ ëŒ€í™” ì´ë ¥ ì¡°í•©
        full_messages = [SystemMessage(content=SYSTEM_PROMPT)] + st.session_state.messages

        full_response = ""
        placeholder = st.empty()
        # LangChain ìŠ¤íŠ¸ë¦¬ë°
        for chunk in llm.stream(full_messages):
            full_response += chunk.content
            placeholder.markdown(full_response + "â–Œ")
        placeholder.markdown(full_response)

    # AI ì‘ë‹µì„ session_stateì— ì €ì¥
    st.session_state.messages.append(AIMessage(content=full_response))
    st.session_state.display_messages.append({"role": "assistant", "content": full_response})